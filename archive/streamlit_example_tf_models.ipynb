{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "450429d6",
   "metadata": {},
   "source": [
    "https://stock-market-prediction-2piq85jecgi.streamlit.app/\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c61c591b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-07-02 15:23:15.045 \n",
      "  \u001b[33m\u001b[1mWarning:\u001b[0m to view this Streamlit app on a browser, run it with the following\n",
      "  command:\n",
      "\n",
      "    streamlit run C:\\Users\\marym\\miniconda3\\envs\\tf\\lib\\site-packages\\ipykernel_launcher.py [ARGUMENTS]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed\n"
     ]
    },
    {
     "ename": "OSError",
     "evalue": "No file or directory found at LSTM_StockPred.h5",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 50\u001b[0m\n\u001b[0;32m     48\u001b[0m df_train \u001b[38;5;241m=\u001b[39m data[[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mDate\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mClose\u001b[39m\u001b[38;5;124m'\u001b[39m]]\n\u001b[0;32m     49\u001b[0m \u001b[38;5;66;03m# df_train = df_train.rename(columns={\"Date\": \"ds\", \"Close\": \"y\"})\u001b[39;00m\n\u001b[1;32m---> 50\u001b[0m lstmModel \u001b[38;5;241m=\u001b[39m \u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkeras\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodels\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_model\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mLSTM_StockPred.h5\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     51\u001b[0m updatedModel \u001b[38;5;241m=\u001b[39m Sequential()\n\u001b[0;32m     53\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m selected_stock \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAAPL\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n",
      "File \u001b[1;32m~\\miniconda3\\envs\\tf\\lib\\site-packages\\keras\\utils\\traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m     68\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[0;32m     69\u001b[0m     \u001b[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[1;32m---> 70\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     71\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m     72\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32m~\\miniconda3\\envs\\tf\\lib\\site-packages\\keras\\saving\\save.py:226\u001b[0m, in \u001b[0;36mload_model\u001b[1;34m(filepath, custom_objects, compile, options)\u001b[0m\n\u001b[0;32m    224\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(filepath_str, \u001b[38;5;28mstr\u001b[39m):\n\u001b[0;32m    225\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mio\u001b[38;5;241m.\u001b[39mgfile\u001b[38;5;241m.\u001b[39mexists(filepath_str):\n\u001b[1;32m--> 226\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mIOError\u001b[39;00m(\n\u001b[0;32m    227\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo file or directory found at \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfilepath_str\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    228\u001b[0m         )\n\u001b[0;32m    230\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mio\u001b[38;5;241m.\u001b[39mgfile\u001b[38;5;241m.\u001b[39misdir(filepath_str):\n\u001b[0;32m    231\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m saved_model_load\u001b[38;5;241m.\u001b[39mload(\n\u001b[0;32m    232\u001b[0m             filepath_str, \u001b[38;5;28mcompile\u001b[39m, options\n\u001b[0;32m    233\u001b[0m         )\n",
      "\u001b[1;31mOSError\u001b[0m: No file or directory found at LSTM_StockPred.h5"
     ]
    }
   ],
   "source": [
    "# pip install streamlit fbprophet yfinance plotly\n",
    "import streamlit as st\n",
    "# import sklearn\n",
    "from datetime import date\n",
    "\n",
    "import yfinance as yf\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from tensorflow.keras.models import Sequential, load_model\n",
    "from tensorflow.keras.layers import LSTM, Dense, Dropout\n",
    "\n",
    "import datetime\n",
    "\n",
    "from statsmodels.tsa.holtwinters import ExponentialSmoothing\n",
    "\n",
    "from plotly import graph_objs as go\n",
    "\n",
    "\n",
    "START = \"2015-01-01\"\n",
    "TODAY = date.today().strftime(\"%Y-%m-%d\")\n",
    "\n",
    "\n",
    "st.title('Stock Prediction Web App')\n",
    "\n",
    "# stocks = ('GOOG', 'AAPL', 'MSFT', 'GME')\n",
    "stocks = (\"AMZN\",\"AAPL\",\"TSLA\" ,\"GOOG\" )\n",
    "selected_stock = st.selectbox('Select dataset for prediction', stocks)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "@st.cache_resource\n",
    "def load_data(ticker):\n",
    "    data = yf.download(ticker, START, TODAY)\n",
    "    data.reset_index(inplace=True)\n",
    "    return data\n",
    "\n",
    "data_load_state = st.text('Loading data...')\n",
    "data = load_data(selected_stock)\n",
    "data_load_state.text('Loading data... done!')\n",
    "flag1 = 0\n",
    "isDone = False\n",
    "\n",
    "# Predict forecast with Prophet.\n",
    "df_train = data[['Date','Close']]\n",
    "# df_train = df_train.rename(columns={\"Date\": \"ds\", \"Close\": \"y\"})\n",
    "lstmModel = tf.keras.models.load_model(\"LSTM_StockPred.h5\")\n",
    "updatedModel = Sequential()\n",
    "\n",
    "if selected_stock == \"AAPL\":\n",
    "\tst.subheader('APPLE Stock')\n",
    "if selected_stock == 'AMZN':\n",
    "\tst.subheader('AMAZON Stock')\n",
    "\tlstmModel = tf.keras.models.load_model(\"modelLSTMamz.h5\")\n",
    "if selected_stock == \"GOOG\":\n",
    "\tst.subheader('GOOGLE Stock')\n",
    "\tlstmModel = tf.keras.models.load_model(\"modelLSTMgog.h5\")\n",
    "\n",
    "if selected_stock == \"TSLA\":\n",
    "\tst.subheader('TESLA Stock')\n",
    "\tlstmModel = tf.keras.models.load_model(\"modelLSTMtsl.h5\")\n",
    "\n",
    "latestData = pd.DataFrame(df_train)\n",
    "latestData = latestData.tail(365)\n",
    "\n",
    "st.subheader('Raw data')\n",
    "st.write(data.tail())\n",
    "\n",
    "def plot_raw_data():\n",
    "\tfig = go.Figure()\n",
    "\tfig.add_trace(go.Scatter(x=data['Date'], y=data['Open'], name=\"stock_open\",line=dict(color='blue')))\n",
    "\tfig.add_trace(go.Scatter(x=data['Date'], y=data['Close'], name=\"stock_close\",line=dict(color='red')))\n",
    "\t# fig.layout.update(title_text='Time Series data with Rangeslider', xaxis_rangeslider_visible=True)\n",
    "\tst.plotly_chart(fig)\n",
    "plot_raw_data()\n",
    "\n",
    "def preprocessData(aplData):\n",
    "\n",
    "\tdef ewm(data, column, window, span):\n",
    "\t\tresult = [0]\n",
    "\t\tfor i in pd.DataFrame.rolling(data[column], window):\n",
    "\t\t\tresult.append(np.mean([k for k in i.ewm(span=span, adjust=False).mean()]))\n",
    "\t\treturn result[:-1]\n",
    "\n",
    "\tdef autocorr(array, column, window, lag=2):\n",
    "\t\tw = window + lag\n",
    "\t\tresult = [0] * (w)\n",
    "\t\tprint(array.shape[0])\n",
    "\t\tfor i in range(w, array.shape[0]):\n",
    "\t\t\tdata = array[column][i - w:i]\n",
    "\t\t\td = data\n",
    "\t\t\ty_bar = np.mean(data)\n",
    "\t\t\tdenominator = sum([(i - y_bar) ** 2 for i in data])\n",
    "\t\t\tlagData = [i - y_bar for i in d][lag:]\n",
    "\t\t\tactualData = [i - y_bar for i in d][:-lag]\n",
    "\t\t\tnumerator = sum(np.array(lagData) * np.array(actualData))\n",
    "\t\t\tresult.append((numerator / denominator))\n",
    "\n",
    "\t\treturn result\n",
    "\n",
    "\tdef doubleExSmoothing(array, column, window, trend):\n",
    "\t\tresult = [0] * (window)\n",
    "\t\tfor i in range(window, array.shape[0]):\n",
    "\t\t\tdata = array[column][i - window:i]\n",
    "\t\t\tvalues = ExponentialSmoothing(data, trend=trend).fit().fittedvalues\n",
    "\t\t\td = [i for i in values.tail(1)]\n",
    "\t\t\tresult.append(d[0])\n",
    "\n",
    "\t\treturn result\n",
    "\n",
    "\n",
    "\taplData['Close'] = aplData['Close'].shift(-1)\n",
    "\tmoving_AverageValues = [10, 20, 50]\n",
    "\tfor i in moving_AverageValues:\n",
    "\t\tcolumn_name = \"MA_%s\" % (str(i))\n",
    "\t\taplData[column_name] = pd.DataFrame.rolling(aplData['Close'], i).mean().shift(1)\n",
    "\taplData['5_day_std'] = aplData['Close'].rolling(window=5).std().shift(1)\n",
    "\taplData['Daily Return'] = aplData['Close'].pct_change().shift(1)\n",
    "\taplData['SD20'] = aplData.Close.rolling(window=20).std().shift(1)\n",
    "\taplData['Upper_Band'] = aplData.Close.rolling(window=20).mean().shift(1) + (aplData['SD20'] * 2)\n",
    "\taplData['Lower_Band'] = aplData.Close.rolling(window=20).mean().shift(1) - (aplData['SD20'] * 2)\n",
    "\taplData['Close(t-1)'] = aplData.Close.shift(periods=1)\n",
    "\taplData['Close(t-2)'] = aplData.Close.shift(periods=2)\n",
    "\taplData['Close(t-5)'] = aplData.Close.shift(periods=5)\n",
    "\taplData['Close(t-10)'] = aplData.Close.shift(periods=10)\n",
    "\taplData['EMA_10'] = ewm(aplData, \"Close\", 50, 10)\n",
    "\taplData['EMA_20'] = ewm(aplData, \"Close\", 50, 20)\n",
    "\taplData['EMA_50'] = ewm(aplData, \"Close\", 50, 50)\n",
    "\taplData['MACD'] = aplData['EMA_10'] - aplData['EMA_20']\n",
    "\taplData['MACD_EMA'] = ewm(aplData, \"MACD\", 50, 9)\n",
    "\taplData['ROC'] = ((aplData['Close'].shift(1) - aplData['Close'].shift(10)) / (aplData['Close'].shift(10))) * 100\n",
    "\tfunct = lambda x: pd.Series(extract_date_features(x))\n",
    "\taplData[['Day', 'DayofWeek', 'DayofYear', 'Week', 'Is_month_end', 'Is_month_start', 'Is_quarter_end',\n",
    "\t\t\t 'Is_quarter_start', 'Is_year_end', 'Is_year_start', 'Is_leap_year', 'Year', 'Month', \"Is_Monday\",\n",
    "\t\t\t \"Is_Tuesday\", \"Is_Wednesday\", \"Is_Thursday\", \"Is_Friday\"]] = aplData[\"Date\"].apply(funct)\n",
    "\taplData['AutoCorr_1'] = autocorr(aplData, 'Close', 10, 1)\n",
    "\taplData['AutoCorr_2'] = autocorr(aplData, 'Close', 10, 2)\n",
    "\taplData['HWES2_ADD'] = doubleExSmoothing(aplData, 'Close', 50, 'additive')\n",
    "\taplData['HWES2_MUL'] = doubleExSmoothing(aplData, 'Close', 50, 'multiplicative')\n",
    "\n",
    "\taplData = aplData.iloc[:-1]\n",
    "\t# aplData = aplData.tail(50)\n",
    "\taplData.reset_index(inplace=True)\n",
    "\taplData = aplData.drop(['index'], axis=1)\n",
    "\treturn aplData\n",
    "\n",
    "def extract_date_features(date_val):\n",
    "\tDay = date_val.day\n",
    "\tDayofWeek = date_val.dayofweek\n",
    "\tDayofyear = date_val.dayofyear\n",
    "\tWeek = date_val.week\n",
    "\tIs_month_end = date_val.is_month_end.real\n",
    "\tIs_month_start = date_val.is_month_start.real\n",
    "\tIs_quarter_end = date_val.is_quarter_end.real\n",
    "\tIs_quarter_start = date_val.is_quarter_start.real\n",
    "\tIs_year_end = date_val.is_year_end.real\n",
    "\tIs_year_start = date_val.is_year_start.real\n",
    "\tIs_leap_year = date_val.is_leap_year.real\n",
    "\tday = date_val.weekday()\n",
    "\tIs_Monday = 1 if day == 0 else 0\n",
    "\tIs_Tuesday = 1 if day == 1 else 0\n",
    "\tIs_Wednesday = 1 if day == 2 else 0\n",
    "\tIs_Thursday = 1 if day == 3 else 0\n",
    "\tIs_Friday = 1 if day == 4 else 0\n",
    "\tYear = date_val.year\n",
    "\tMonth = date_val.month\n",
    "\n",
    "\treturn Day, DayofWeek, Dayofyear, Week, Is_month_end, Is_month_start, Is_quarter_end, Is_quarter_start, Is_year_end, Is_year_start, Is_leap_year, Year, Month, Is_Monday, Is_Tuesday, Is_Wednesday, Is_Thursday, Is_Friday\n",
    "\n",
    "def extractFeatures(lastFeatures, y_train, date):\n",
    "\t'''Function used to extract input features based on previous close price and date value\n",
    "     lastFeatures - last few values (features)\n",
    "     y_train - close price values\n",
    "     date - current date\n",
    "     return - all input features '''\n",
    "\n",
    "\n",
    "\n",
    "\tdef autocorr(array, window, lag=2):\n",
    "\t\tw = window + lag\n",
    "\n",
    "\t\tdata = array\n",
    "\t\td = data\n",
    "\t\ty_bar = np.mean(data)\n",
    "\t\tdenominator = sum([(i - y_bar) ** 2 for i in data])\n",
    "\t\tlagData = [i - y_bar for i in d][lag:]\n",
    "\t\tactualData = [i - y_bar for i in d][:-lag]\n",
    "\t\tnumerator = sum(np.array(lagData) * np.array(actualData))\n",
    "\n",
    "\t\treturn numerator / denominator\n",
    "\n",
    "\tdef doubleExSmoothing(array, trend):\n",
    "\t\tdata = array\n",
    "\t\tvalues = ExponentialSmoothing(data, trend=trend).fit().fittedvalues\n",
    "\t\td = [i for i in values.tail(1)]\n",
    "\t\t#     result.append( d[0])\n",
    "\n",
    "\t\treturn d[0]\n",
    "\n",
    "\tcurrentData = {i: {None} for i in lastFeatures.columns}\n",
    "\tif lastFeatures.shape[0] > 50 or True:\n",
    "\t\tlastFeatures = lastFeatures.tail(50)\n",
    "\t\tlastValue = lastFeatures.iloc[-1]\n",
    "\n",
    "\t\tend_date = date\n",
    "\n",
    "\t\tday = pd.to_datetime(end_date).weekday()\n",
    "\t\tif day <= 4:\n",
    "\n",
    "\t\t\tcurrentData['MA_10'] = y_train.tail(10).mean()\n",
    "\t\t\tcurrentData['MA_20'] = y_train.tail(20).mean()\n",
    "\t\t\tcurrentData['MA_50'] = y_train.tail(50).mean()\n",
    "\t\t\tcurrentData['5_day_std'] = y_train.tail(5).std()\n",
    "\t\t\t#             currentData['SD20'] = y_train.tail(20).rolling(window=20).std().iloc[-1]\n",
    "\t\t\tcurrentData['SD20'] = y_train.tail(20).std()\n",
    "\t\t\tcurrentData['Daily Return'] = y_train.tail(2).pct_change().iloc[-1]\n",
    "\t\t\tcurrentData['Upper_Band'] = (y_train.tail(20).mean() + (currentData['SD20'] * 2))\n",
    "\t\t\tcurrentData['Lower_Band'] = (y_train.tail(20).mean() - (currentData['SD20'] * 2))\n",
    "\t\t\t#             print(currentData['Upper_Band'])\n",
    "\t\t\tcurrentData['Close(t-1)'] = y_train.iloc[-1]\n",
    "\t\t\tcurrentData['Close(t-2)'] = y_train.iloc[-2]\n",
    "\t\t\tcurrentData['Close(t-5)'] = y_train.iloc[-5]\n",
    "\t\t\tcurrentData['Close(t-10)'] = y_train.iloc[-10]\n",
    "\n",
    "\t\t\t#             aplData['EMA_10'] = ewm(aplData, \"Close\",50,10)\n",
    "\t\t\tcurrentData['EMA_10'] = np.mean(y_train.tail(50).ewm(span=10, adjust=False).mean())\n",
    "\t\t\tcurrentData['EMA_20'] = np.mean(y_train.tail(50).ewm(span=20, adjust=False).mean())\n",
    "\n",
    "\n",
    "\t\t\tcurrentData['EMA_50'] = np.mean(y_train.tail(50).ewm(span=50, adjust=False).mean())\n",
    "\t\t\tcurrentData['MACD'] = currentData['EMA_10'] - currentData['EMA_20']\n",
    "\t\t\tcurrentData['MACD_EMA'] = np.mean(lastFeatures['MACD'].tail(50).ewm(span=9, adjust=False).mean())\n",
    "\t\t\t#             currentData['MACD_EMA'] = lastFeatures['MACD'].tail(50).ewm(span=9, adjust=False).mean().iloc[-1]\n",
    "\t\t\tcurrentData['ROC'] = ((y_train.iloc[-1] - y_train.iloc[-10]) / (y_train.iloc[-10])) * 100\n",
    "\t\t\tresult = list(extract_date_features(end_date))\n",
    "\n",
    "\t\t\tfor i, v in enumerate(\n",
    "\t\t\t\t\t['Day', 'DayofWeek', 'DayofYear', 'Week', 'Is_month_end', 'Is_month_start', 'Is_quarter_end',\n",
    "\t\t\t\t\t 'Is_quarter_start', 'Is_year_end', 'Is_year_start', 'Is_leap_year', \"Year\", 'Month', \"Is_Monday\",\n",
    "\t\t\t\t\t \"Is_Tuesday\", \"Is_Wednesday\", \"Is_Thursday\", \"Is_Friday\"]):\n",
    "\t\t\t\tcurrentData[v] = result[i]\n",
    "\t\t\tcurrentData[\"AutoCorr_1\"] = autocorr(y_train.tail(11), 10, lag=1)\n",
    "\t\t\tcurrentData[\"AutoCorr_2\"] = autocorr(y_train.tail(12), 10, lag=2)\n",
    "\t\t\tcurrentData[\"HWES2_MUL\"] = doubleExSmoothing(y_train.tail(50), 'multiplicative')\n",
    "\t\t\tcurrentData['HWES2_ADD'] = doubleExSmoothing(y_train.tail(50), 'additive')\n",
    "\t\telse:\n",
    "\t\t\tpass\n",
    "\n",
    "\n",
    "\treturn currentData\n",
    "\n",
    "def predictFuture(Nday,X_train,y_train,model):\n",
    "\tlastFeatures, lastPriceValues = pd.DataFrame(X_train).tail(50), y_train.tail(50)\n",
    "\tdate = \"{}/{}/{}\".format(int(lastFeatures.iloc[-1]['Month']), int(lastFeatures.iloc[-1]['Day']),\n",
    "\t\t\t\t\t\t\t int(lastFeatures.iloc[-1]['Year']))\n",
    "\tstartDate = pd.to_datetime(date) + datetime.timedelta(days=1)\n",
    "\tlastDate = date\n",
    "\tpredValues = []\n",
    "\ttotalDates = []\n",
    "\ti = 1\n",
    "\tfi = []\n",
    "\twhile i <= Nday:\n",
    "\t\tend_date = pd.to_datetime(date) + datetime.timedelta(days=1)\n",
    "\t\tdate = end_date\n",
    "\t\tday = pd.to_datetime(end_date).weekday()\n",
    "\t\tif day <= 4:\n",
    "\t\t\ti += 1\n",
    "\t\t\tlastDate = end_date\n",
    "\t\t\tif i == 2:\n",
    "\t\t\t\tstartDate = end_date\n",
    "\t\t\tcurrentData = extractFeatures(lastFeatures, lastPriceValues, end_date)\n",
    "\n",
    "\t\t\tdf = {k: [v] for k, v in currentData.items()}\n",
    "\t\t\tdf[\"Date\"] = end_date\n",
    "\t\t\ttotalDates.append(end_date)\n",
    "\n",
    "\t\t\tdf = pd.DataFrame(df)\n",
    "\n",
    "\n",
    "\t\t\tdf3 = pd.concat([lastFeatures, df], ignore_index=True)\n",
    "\n",
    "\t\t\tinputFeature = df3.drop([\"Date\"],axis = 1).iloc[-1]\n",
    "\n",
    "\t\t\tinpu = np.array([i for i in inputFeature])\n",
    "\n",
    "\t\t\tinpu = sX_val.transform(inpu.reshape(1, -1))\n",
    "\n",
    "\n",
    "\t\t\tinpu = inpu.reshape(1, X_train.shape[1]-1, 1)\n",
    "\n",
    "\n",
    "\t\t\tpred = model.predict(inpu, verbose=0)\n",
    "\n",
    "\n",
    "\t\t\tpred = sY_val.inverse_transform(pred.reshape(-1, 1))\n",
    "\n",
    "\t\t\tpredValues.append(pred[0][0])\n",
    "\t\t\tlastFeatures = df3.tail(50)\n",
    "\t\t\tlastPriceValues = list(lastPriceValues)\n",
    "\t\t\tlastPriceValues.append(pred[0][0])\n",
    "\t\t\tlastPriceValues = pd.Series(lastPriceValues)\n",
    "\t\t\tlastPriceValues = lastPriceValues.tail(50)\n",
    "\n",
    "\n",
    "\tdf3[\"pred\"] = lastPriceValues\n",
    "\tpredictions = pd.DataFrame(data = [np.array(totalDates),np.array(predValues)]).T\n",
    "\tpredictions.columns = ['Date', 'pred']\n",
    "\n",
    "\treturn predictions\n",
    "\n",
    "def modelTrain(xtrain,ytrain,modelLSTMs,epochs = 50):\n",
    "\tmodelLSTM = modelLSTMs\n",
    "\tmodelLSTM.compile(loss = 'mae', optimizer='adam')\n",
    "\tmodelLSTM.fit(xtrain, ytrain, epochs=epochs, batch_size=16)\n",
    "\treturn modelLSTM\n",
    "    \n",
    "\n",
    "n_days = st.slider('Please enter number of days for prediction:', 0, 365)\n",
    "period = n_days\n",
    "Ndays = n_days\n",
    "\n",
    "if Ndays>0  :\n",
    "\tpredict_state = st.text('Processing Data, Please wait...')\n",
    "\tinputData = preprocessData(latestData)\n",
    "\tpredict_state.text('')\n",
    "\n",
    "\ty_test = inputData[\"Close\"].tail(100)\n",
    "\tx_test = inputData.drop([\"Close\"], axis=1).tail(100)\n",
    "\tmodelData = inputData.iloc[51:-100,:]\n",
    "\txtrain = modelData.drop([\"Close\"], axis=1)\n",
    "\tytrain = modelData[\"Close\"]\n",
    "\tsX_train = MinMaxScaler(feature_range=(0, 1))\n",
    "\tsY_train = MinMaxScaler(feature_range=(0, 1))\n",
    "\n",
    "\tX_train = sX_train.fit_transform(np.array(xtrain.drop([\"Date\"], axis=1))).reshape(xtrain.shape[0],\n",
    "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t   xtrain.shape[1] - 1, 1)\n",
    "\tY_train = sY_train.fit_transform(np.array(ytrain).reshape(-1, 1)).reshape(ytrain.shape[0], )\n",
    "\n",
    "\n",
    "\tsX_val = MinMaxScaler(feature_range=(0, 1))\n",
    "\tsY_val = MinMaxScaler(feature_range=(0, 1))\n",
    "\tX_valLSTM = sX_val.fit_transform(np.array(x_test.drop([\"Date\"], axis=1))).reshape(x_test.shape[0],\n",
    "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t   x_test.shape[1] - 1, 1)\n",
    "\ty_valLSTM = sY_val.fit_transform(np.array(y_test).reshape(-1, 1)).reshape(y_test.shape[0], )\n",
    "\n",
    "\tst.write(\"Re-train : This will update the existing model by re training it with latest data and predicts the price\")\n",
    "\tst.write(\"**********************************************************************************\")\n",
    "\tst.write(\"Predict : Predicts the future stock price using old trained model\")\n",
    "\tpredict_state1 = st.text(\"Click the below button, if wanted to update the model\")\n",
    "\n",
    "\t\n",
    "\tif st.button(\"Re-Train Model and Predict(optional)time < 3 min)\"):\n",
    "\t\tpredict_state1.text(' Training...')\n",
    "\t\tpredict_state1.text(' Training..........')\n",
    "\t\tpredict_state1.text(' Training.........................')\n",
    "\t\tpredict_state1.text(' Training.......................................')\n",
    "\t\tpredict_state1.text(' Training......................................................')\n",
    "\t\t\n",
    "\t\tupdatedModel = modelTrain(X_train,Y_train,lstmModel)\n",
    "\t\t# predict_state1.text(' Finished!. Click on predict')\n",
    "\t\tflag1 = 1\n",
    "\t\tpredict_state1.text(\"Please wait..\")\n",
    "\n",
    "        \n",
    "\t\t\n",
    "\t\t# model = lstmModel if flag1==0 else updatedModel\n",
    "\t\t# st.write(\"is flag1 {}\".format(str(flag1)))\n",
    "\t\tpredictions = predictFuture(Ndays,x_test,y_test,updatedModel)\n",
    "\t\tst.write(\"Prediction is Done!,results are displayed below\")\n",
    "# \t\tpredictions.iloc[0] =  df_train.iloc[-1]\n",
    "#                 predictions[\"Date\"].iloc[0] = data[\"Date\"].iloc[-1]\n",
    "# \t\tpredictions[\"pred\"].iloc[0] = data[\"Close\"].iloc[-1]\n",
    "\t\tpredict_state1.text(\"Done\")\n",
    "\t\t# Show and plot forecast\n",
    "\t\tst.subheader('Forecasted data')\n",
    "\t\tst.write(predictions)\n",
    "# \t\tst.write(predictions.iloc[0])\n",
    "\n",
    "\t\tst.write(f'Forecast plot for {Ndays} days')\n",
    "\n",
    "\t\tfig = go.Figure()\n",
    "\t\tfig.add_trace(go.Scatter(x=predictions['Date'], y=predictions['pred'],name=\"Prediction\"))\n",
    "\t\tfig.add_trace(go.Scatter(x=data['Date'].tail(1000), y=data['Close'].tail(1000), name=\"stock_close\"))\n",
    "\t\tst.plotly_chart(fig)\n",
    "\n",
    "\t\tst.write(\"Percentage gain or loss for next {} days prediction \".format(Ndays))\n",
    "\t\tst.write(\"Predicted price is {} on {} \".format(predictions[\"pred\"].iloc[-1],predictions[\"Date\"].iloc[-1]))\n",
    "\t\tprofit = ((predictions[\"pred\"].iloc[-1] - data['Close'].iloc[-1]  ) / data['Close'].iloc[-1])* 100\n",
    "\t\tst.write(\"{} percentage\".format(np.round(profit,3)))\n",
    "\t\tfor i in range(3):\n",
    "\t\t\tst.write(\"*\"*3)\n",
    "\t\t\n",
    "\n",
    "\t\tst.write(\"Note : Models are trained only based on technical data. Future plans are to include both fundamental and economical factors real timely to get a robust prediction.\")\n",
    "\n",
    "\n",
    "\n",
    "\tif st.button(\"Predict using pre trained model\") :\n",
    "\t\tpredict_state1.text(\"Please wait..\")\n",
    "\n",
    "        \n",
    "\t\t\n",
    "\t\t# model = lstmModel if flag1==0 else updatedModel\n",
    "\t\t# st.write(\"is flag1 {}\".format(str(flag1)))\n",
    "\t\tpredictions = predictFuture(Ndays,x_test,y_test,lstmModel)\n",
    "\t\tst.write(\"Prediction is Done!,results are displayed below\")\n",
    "# \t\tpredictions.iloc[0] =  df_train.iloc[-1]\n",
    "#                 predictions[\"Date\"].iloc[0] = data[\"Date\"].iloc[-1]\n",
    "# \t\tpredictions[\"pred\"].iloc[0] = data[\"Close\"].iloc[-1]\n",
    "\t\tpredict_state1.text(\"Done\")\n",
    "\t\t# Show and plot forecast\n",
    "\t\tst.subheader('Forecasted data')\n",
    "\t\tst.write(predictions)\n",
    "# \t\tst.write(predictions.iloc[0])\n",
    "\n",
    "\t\tst.write(f'Forecast plot for {Ndays} days')\n",
    "\n",
    "\t\tfig = go.Figure()\n",
    "\t\tfig.add_trace(go.Scatter(x=predictions['Date'], y=predictions['pred'],name=\"Prediction\"))\n",
    "\t\tfig.add_trace(go.Scatter(x=data['Date'].tail(1000), y=data['Close'].tail(1000), name=\"stock_close\"))\n",
    "\t\tst.plotly_chart(fig)\n",
    "\n",
    "\t\tst.write(\"Percentage gain or loss for next {} days prediction \".format(Ndays))\n",
    "\t\tst.write(\"Predicted price is {} on {} \".format(predictions[\"pred\"].iloc[-1],predictions[\"Date\"].iloc[-1]))\n",
    "\t\tprofit = ((predictions[\"pred\"].iloc[-1] - data['Close'].iloc[-1]  ) / data['Close'].iloc[-1])* 100\n",
    "\t\tst.write(\"{} percentage\".format(np.round(profit,3)))\n",
    "\t\tfor i in range(3):\n",
    "\t\t\tst.write(\"*\"*3)\n",
    "\t\t\n",
    "\n",
    "\t\tst.write(\"Note : Models are trained only based on technical data. Future plans are to include both fundamental and economical factors real timely to get a robust prediction.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f07616e2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:tf]",
   "language": "python",
   "name": "conda-env-tf-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
